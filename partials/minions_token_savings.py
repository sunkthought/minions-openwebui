# Partials File: partials/minions_token_savings.py
from typing import List, Dict, Any

# Placeholder for actual Valves type if needed by this function in the future,
# though current implementation does not use it directly.
# from .minions_valves import MinionsValves as ValvesType
ValvesType = Any 

def calculate_minions_token_savings(
    # valves: ValvesType, # Not strictly needed by current logic but kept for consistency if future versions use it
    decomposition_prompts: List[str], 
    synthesis_prompts: List[str],
    all_results_summary_for_remote: str,
    final_response_remote: str,
    context_length: int, 
    query_length: int,
    chars_per_token: float = 3.5  # Average characters per token
) -> Dict[str, Any]:
    """
    Calculates token savings for the MinionS protocol by comparing estimated tokens
    for a traditional single remote model call versus the actual remote model calls
    made during the MinionS protocol (decomposition and synthesis phases).

    Args:
        decomposition_prompts: List of prompts sent for task decomposition.
        synthesis_prompts: List of prompts sent for final synthesis.
        all_results_summary_for_remote: The summary of all local model findings sent for synthesis.
        final_response_remote: The final response from the remote model after synthesis.
        context_length: Length of the original full context.
        query_length: Length of the original user query.
        chars_per_token: Estimated average characters per token.

    Returns:
        A dictionary containing token usage and savings statistics for remote model calls.
    """
    # Tokens for traditional approach (full context + query to remote model)
    traditional_tokens_remote = int((context_length + query_length) / chars_per_token)
    
    # Tokens for MinionS approach (sum of all actual calls to remote model)
    minions_tokens_remote = 0
    
    # Add tokens from decomposition prompts
    for prompt_content in decomposition_prompts:
        minions_tokens_remote += int(len(prompt_content) / chars_per_token)
    
    # Add tokens from synthesis prompts
    for prompt_content in synthesis_prompts:
        minions_tokens_remote += int(len(prompt_content) / chars_per_token)
        
    # Add tokens from the summary of results sent during synthesis
    minions_tokens_remote += int(len(all_results_summary_for_remote) / chars_per_token)
    
    # Add tokens from the final response generated by the remote model
    minions_tokens_remote += int(len(final_response_remote) / chars_per_token)
    
    token_savings_remote = traditional_tokens_remote - minions_tokens_remote
    percentage_savings_remote = (token_savings_remote / traditional_tokens_remote * 100) if traditional_tokens_remote > 0 else 0
    
    return {
        'traditional_tokens_remote': traditional_tokens_remote,
        'minions_tokens_remote': minions_tokens_remote,
        'token_savings_remote': token_savings_remote,
        'percentage_savings_remote': percentage_savings_remote,
        'total_decomposition_rounds': len(decomposition_prompts) # Informational
    }
